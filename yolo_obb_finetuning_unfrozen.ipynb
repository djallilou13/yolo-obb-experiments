{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO-OBB Full Fine-Tuning (Strategy B: Unfrozen)\n",
    "\n",
    "**Strategy B: Full Fine Tuning (Unfrozen):**\n",
    "Similar to Strategy A, the model is pretrained on synthetic data. However, in this phase, **all layers are unfrozen** (freeze parameter = 0), allowing the gradients to update the entire network from the backbone to the head on the real world subsets. This evaluates whether allowing the model to adjust its deep feature representations to the real domain yields better adaptation than head only training.\n",
    "\n",
    "**Structure:**\n",
    "1. **Setup**: Imports, Google Drive mount, W&B login, and Configuration.\n",
    "2. **Data Preparation**: Helper functions to split and subset real data.\n",
    "3. **Training Cells**: \n",
    "    - Cells 1-5: Fine-tune synthetic model on 5%, 10%, 20%, 30%, 40% of real data.\n",
    "    - Cell 6: Train from scratch (Baseline) on Alpha% of real data.\n",
    "\n",
    "> **IMPORTANT**: Update `REAL_DATASET_PATH`, `SYNTHETIC_MODEL_PATH`, and `BASE_MODEL_PATH` below before running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics albumentations opencv-python numpy pyyaml tqdm scikit-learn wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup & Imports\n",
    "# Fix environment dependency issues (typing_extensions mismatch with pydantic/wandb)\n",
    "# Run this FIRST before importing anything else\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "# Uncomment and run this once, then restart your kernel\n",
    "# fix_dependencies()\n",
    "\n",
    "# ============================================================\n",
    "# AFTER RESTARTING KERNEL, RUN FROM HERE:\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup & Imports\n",
    "# Fix environment dependency issues (typing_extensions mismatch with pydantic/wandb)\n",
    "# Run this FIRST before importing anything else\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def fix_dependencies():\n",
    "    \"\"\"Fix typing_extensions and pydantic version conflicts\"\"\"\n",
    "    print(\"Fixing dependency conflicts...\")\n",
    "    \n",
    "    # Upgrade typing_extensions first\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \n",
    "                          \"--upgrade\", \"--user\", \"typing_extensions>=4.6.0\"])\n",
    "    \n",
    "    # Then upgrade pydantic and wandb\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \n",
    "                          \"--upgrade\", \"--user\", \"pydantic>=2.0\", \"wandb\"])\n",
    "    \n",
    "    print(\"Dependencies fixed. Please restart your kernel/runtime!\")\n",
    "    print(\"After restarting, run the rest of your code.\")\n",
    "\n",
    "# Uncomment and run this once, then restart your kernel\n",
    "# fix_dependencies()\n",
    "\n",
    "# ============================================================\n",
    "# AFTER RESTARTING KERNEL, RUN FROM HERE:\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# [Action Required] Update these paths\n",
    "REAL_DATASET_PATH = Path(\"Real_Data/train(80_ REAL DATA)\") \n",
    "TEST_DATASET_PATH=Path(\"last-test\")\n",
    "SYNTHETIC_MODEL_PATH = \"YOLO26l_OBB_E1_Synthesized_only2/weights/best.pt\"\n",
    "BASE_MODEL_PATH = \"yolo26l-obb.pt\" # [Action Required] Path to base model for scratch training baseline\n",
    "DRIVE_UPLOAD_FOLDER = Path(\"YOLO_OBB_FineTuning_Results\")  # Local path for school server\n",
    "\n",
    "# W&B Configuration\n",
    "WANDB_PROJECT = \"paper_experiment_mixed\"\n",
    "WANDB_ENTITY = \"abd-eldjalil-taibi-ensia\" # Or your entity\n",
    "\n",
    "# Training Hyperparameters (Optimized for Fine-tuning)\n",
    "FINETUNE_CONFIG = {\n",
    "    \"epochs\": 100,\n",
    "    \"imgsz\": 640,\n",
    "    \"batch\": 12,\n",
    "    \"workers\": 20,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"lr0\": 0.0005, # Lower LR for fine-tuning (was 0.001) to preserve features\n",
    "    \"lrf\": 0.01,\n",
    "    \"momentum\": 0.937,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"close_mosaic\": 15,\n",
    "    \"patience\": 25,\n",
    "    \"save_period\": 10,\n",
    "    \"val\": True,\n",
    "    \"amp\": True,\n",
    "    \"device\": 0,\n",
    "    \"freeze\": 0, # Unfrozen: Update all layers (Strategy B)\n",
    "    \"warmup_epochs\": 1.0, # Reduced warmup for fine-tuning\n",
    "    # Augmentations (Matches reference training loop)\n",
    "    \"hsv_h\": 0.015, \"hsv_s\": 0.7, \"hsv_v\": 0.4,\n",
    "    \"degrees\": 10.0,\n",
    "    \"translate\": 0.1,\n",
    "    \"scale\": 0.9,\n",
    "    \"fliplr\": 0.5,\n",
    "    \"mosaic\": 1.0,\n",
    "    \"mixup\": 0.1,\n",
    "    \"erasing\": 0.3,\n",
    "    \"perspective\": 0.0005,\n",
    "}\n",
    "\n",
    "# Training Hyperparameters (From Reference - For Scratch/Baseline Training)\n",
    "SCRATCH_CONFIG = {\n",
    "    \"epochs\": 100,\n",
    "    \"imgsz\": 640,\n",
    "    \"batch\": 12,\n",
    "    \"workers\": 20,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"lr0\": 0.001, # High LR for scratch training\n",
    "    \"lrf\": 0.01,\n",
    "    \"momentum\": 0.937,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"close_mosaic\": 15,\n",
    "    \"patience\": 25,\n",
    "    \"save_period\": 10,\n",
    "    \"val\": True,\n",
    "    \"amp\": True,\n",
    "    \"device\": 0,\n",
    "    # No freezing for scratch training\n",
    "    \n",
    "    # Augmentations (Matches reference training loop)\n",
    "    \"hsv_h\": 0.015, \"hsv_s\": 0.7, \"hsv_v\": 0.4,\n",
    "    \"degrees\": 10.0,\n",
    "    \"translate\": 0.1,\n",
    "    \"scale\": 0.9,\n",
    "    \"fliplr\": 0.5,\n",
    "    \"mosaic\": 1.0,\n",
    "    \"mixup\": 0.1,\n",
    "    \"erasing\": 0.3,\n",
    "    \"perspective\": 0.0005,\n",
    "}\n",
    "\n",
    "IMG_EXTS = [\".jpg\", \".jpeg\", \".png\"]\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Create output directory\n",
    "DRIVE_UPLOAD_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Login to W&B\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "print(\"Setup complete! Ready for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- CONFIGURATION FOR SPLITS ---\n",
    "# We run this ONCE to ensure every experiment uses the exact same validation set.\n",
    "INTERNAL_TRAIN_LIST = Path(\"internal_train_list.txt\")\n",
    "INTERNAL_VAL_LIST = Path(\"internal_val_list.txt\")\n",
    "\n",
    "def prepare_fixed_splits(real_dataset_path):\n",
    "    \"\"\"\n",
    "    Scans the REAL_DATASET_PATH (your 80% chunk) and creates:\n",
    "    1. A fixed Internal Validation set (20% of this chunk).\n",
    "    2. A fixed Internal Training pool (80% of this chunk).\n",
    "    Saves them to text files so they never change between runs.\n",
    "    \"\"\"\n",
    "    if INTERNAL_TRAIN_LIST.exists() and INTERNAL_VAL_LIST.exists():\n",
    "        print(\"\u2705 Fixed splits already exist. Using existing lists.\")\n",
    "        return\n",
    "\n",
    "    print(\"\u26a0\ufe0f Generating new fixed splits from Real Data...\")\n",
    "    images_dir = real_dataset_path / \"images\"\n",
    "    \n",
    "    # 1. Gather all images\n",
    "    all_images = []\n",
    "    # Assuming IMG_EXTS is defined earlier, e.g., ['.jpg', '.png', '.jpeg']\n",
    "    for ext in IMG_EXTS:\n",
    "        all_images.extend(images_dir.rglob(f\"*{ext}\"))\n",
    "    \n",
    "    all_images = sorted(list(set(all_images)))\n",
    "    \n",
    "    # 2. Shuffle with a FIXED SEED\n",
    "    random.seed(42) \n",
    "    random.shuffle(all_images)\n",
    "    \n",
    "    # 3. Split 80/20 (Internal Train / Internal Val)\n",
    "    split_idx = int(len(all_images) * 0.8)\n",
    "    train_pool = all_images[:split_idx]\n",
    "    val_pool = all_images[split_idx:]\n",
    "    \n",
    "    # 4. Save to disk\n",
    "    with open(INTERNAL_TRAIN_LIST, 'w') as f:\n",
    "        f.write('\\n'.join([str(p.resolve()) for p in train_pool]))\n",
    "        \n",
    "    with open(INTERNAL_VAL_LIST, 'w') as f:\n",
    "        f.write('\\n'.join([str(p.resolve()) for p in val_pool]))\n",
    "        \n",
    "    print(f\"Split Complete: {len(train_pool)} Train, {len(val_pool)} Val.\")\n",
    "    print(\"Lists saved to disk.\")\n",
    "\n",
    "def create_subset_yaml(percentage, run_name):\n",
    "    \"\"\"\n",
    "    Creates a YAML file using the FIXED Internal Val set and a SUBSET of the Internal Train set.\n",
    "    Also links the External Test set.\n",
    "    \"\"\"\n",
    "    # 1. Read the Master Train Pool\n",
    "    with open(INTERNAL_TRAIN_LIST, 'r') as f:\n",
    "        full_train = [x.strip() for x in f.readlines() if x.strip()]\n",
    "        \n",
    "    # 2. Create the Subset (e.g., 10% of the train pool)\n",
    "    subset_size = int(len(full_train) * percentage)\n",
    "    train_subset = full_train[:subset_size]\n",
    "    \n",
    "    # Save the specific subset list for this run\n",
    "    train_subset_path = Path(f\"{run_name}_train.txt\")\n",
    "    with open(train_subset_path, 'w') as f:\n",
    "        f.write('\\n'.join(train_subset))\n",
    "        \n",
    "    print(f\"[{run_name}] Training on {len(train_subset)} images (Subset of {len(full_train)})\")\n",
    "    \n",
    "    # 3. Define path for External Test Set\n",
    "    # We assume your test images are in TEST_DATASET_PATH / \"images\"\n",
    "    # If your TEST_DATASET_PATH is already a .txt list, use that instead.\n",
    "    test_images_dir = TEST_DATASET_PATH / \"images\" \n",
    "    \n",
    "    # 4. Create YAML\n",
    "    # TRAIN: The subset we just made\n",
    "    # VAL: The fixed internal validation list\n",
    "    # TEST: The external folder\n",
    "    yaml_content = f\"\"\"\n",
    "path: {Path.cwd()}\n",
    "train: {train_subset_path.resolve()}\n",
    "val: {INTERNAL_VAL_LIST.resolve()}\n",
    "test: {test_images_dir.resolve()}\n",
    "\n",
    "nc: 1\n",
    "names: ['object']\n",
    "\"\"\"\n",
    "    yaml_path = Path(f\"{run_name}_dataset.yaml\")\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "        \n",
    "    return yaml_path\n",
    "\n",
    "def run_finetuning(percentage, run_name_suffix):\n",
    "    run_name = f\"yolo_obb_ft_{run_name_suffix}\"\n",
    "    \n",
    "    # 1. Prepare Data (Uses the fixed splits)\n",
    "    dataset_yaml = create_subset_yaml(percentage, run_name)\n",
    "    \n",
    "    # 2. Load Model\n",
    "    model = YOLO(SYNTHETIC_MODEL_PATH)\n",
    "    \n",
    "    # 3. Train\n",
    "    # The model will use 'val' (Internal Val) to decide when to stop / save best weights.\n",
    "    model.train(\n",
    "        data=str(dataset_yaml),\n",
    "        project=WANDB_PROJECT,\n",
    "        name=run_name,\n",
    "        **FINETUNE_CONFIG\n",
    "    )\n",
    "    \n",
    "    # 4. Save & Upload\n",
    "    best_weights = Path(model.trainer.save_dir) / \"weights\" / \"best.pt\"\n",
    "    target_name = f\"{run_name}.pt\"\n",
    "    target_path = DRIVE_UPLOAD_FOLDER / target_name\n",
    "    \n",
    "    if best_weights.exists():\n",
    "        print(f\"Uploading {best_weights} to {target_path}...\")\n",
    "        shutil.copy(best_weights, target_path)\n",
    "    else:\n",
    "        print(\"Warning: Best weights file not found.\")\n",
    "\n",
    "def run_training_scratch(percentage, run_name_suffix):\n",
    "    \"\"\"\n",
    "    Trains from scratch/baseline using the same fixed splits.\n",
    "    \"\"\"\n",
    "    run_name = f\"yolo_obb_scratch_{run_name_suffix}\"\n",
    "    \n",
    "    dataset_yaml = create_subset_yaml(percentage, run_name)\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(BASE_MODEL_PATH) \n",
    "    except Exception as e:\n",
    "        model = YOLO(\"yolo11l-obb.pt\")\n",
    "\n",
    "    model.train(\n",
    "        data=str(dataset_yaml),\n",
    "        project=WANDB_PROJECT,\n",
    "        name=run_name,\n",
    "        **SCRATCH_CONFIG\n",
    "    )\n",
    "    \n",
    "    best_weights = Path(model.trainer.save_dir) / \"weights\" / \"best.pt\"\n",
    "    target_name = f\"{run_name}.pt\"\n",
    "    target_path = DRIVE_UPLOAD_FOLDER / target_name\n",
    "    \n",
    "    if best_weights.exists():\n",
    "        print(f\"Uploading {best_weights} to {target_path}...\")\n",
    "        shutil.copy(best_weights, target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 5% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fixed_splits(REAL_DATASET_PATH)\n",
    "# Cell 1: 5% Fine-tuning\n",
    "run_finetuning(percentage=0.05, run_name_suffix=\"5pct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 10% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fixed_splits(REAL_DATASET_PATH)\n",
    "# Cell 2: 10% Fine-tuning\n",
    "run_finetuning(percentage=0.10, run_name_suffix=\"10pct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 20% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fixed_splits(REAL_DATASET_PATH)\n",
    "# Cell 3: 20% Fine-tuning\n",
    "run_finetuning(percentage=0.20, run_name_suffix=\"20pct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 30% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fixed_splits(REAL_DATASET_PATH)\n",
    "# Cell 4: 30% Fine-tuning\n",
    "run_finetuning(percentage=0.30, run_name_suffix=\"30pct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 40% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fixed_splits(REAL_DATASET_PATH)\n",
    "# Cell 5: 40% Fine-tuning\n",
    "run_finetuning(percentage=0.40, run_name_suffix=\"40pct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 50% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fixed_splits(REAL_DATASET_PATH)\n",
    "# Cell 5: 50% Fine-tuning\n",
    "run_finetuning(percentage=0.50, run_name_suffix=\"50pct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Scratch Training (40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_pct = 0.40 # [Editable] Change this variable to your desired percentage (0.0 to 1.0)\n",
    "\n",
    "run_training_scratch(percentage=alpha_pct, run_name_suffix=\"alpha_baseline_40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Scratch Training (Alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Alpha% Scratch Training (Baseline)\n",
    "# This trains from the BASE model (not synthetic) to establish a baseline for comparison.\n",
    "alpha_pct = 0.50 # [Editable] Change this variable to your desired percentage (0.0 to 1.0)\n",
    "\n",
    "run_training_scratch(percentage=alpha_pct, run_name_suffix=\"alpha_baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Models Testing on Real Data\n",
    "\n",
    "This section evaluates the fine-tuned models on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Test Data\n",
    "TEST_DATASET_PATH = Path(\"last-test\")\n",
    "\n",
    "def create_test_yaml(test_path, run_name):\n",
    "    \"\"\"\n",
    "    Creates a YAML file for the test dataset.\n",
    "    \"\"\"\n",
    "    images_dir = test_path / \"images\"\n",
    "    \n",
    "    # Scan all valid image files\n",
    "    test_images = []\n",
    "    for ext in IMG_EXTS:\n",
    "        test_images.extend(images_dir.rglob(f\"*{ext}\"))\n",
    "        \n",
    "    test_images = sorted(list(set(test_images)))\n",
    "    print(f\"[{run_name}] Total Test Images: {len(test_images)}\")\n",
    "    \n",
    "    # Create txt path\n",
    "    test_txt_path = Path(f\"{run_name}_test.txt\")\n",
    "    \n",
    "    with open(test_txt_path, 'w') as f:\n",
    "        f.write('\\n'.join([str(p.resolve()) for p in test_images]))\n",
    "        \n",
    "    # Create YAML\n",
    "    yaml_content = f\"\"\"\n",
    "path: {Path.cwd()}\n",
    "train: {test_txt_path.resolve()} # Not used for validation but required\n",
    "val: {test_txt_path.resolve()}  # Used for validation\n",
    "test: {test_txt_path.resolve()} # Used for prediction/testing\n",
    "\n",
    "nc: 1\n",
    "names: ['object']\n",
    "\"\"\"\n",
    "    yaml_path = Path(f\"{run_name}_test_dataset.yaml\")\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "        \n",
    "    return yaml_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Evaluation on All Models\n",
    "# Paths are relative to the notebook location (runs/obb/...)\n",
    "models_to_test = [\n",
    "    \"YOLO_OBB_Mixed_Training_Results/yolo26l_mixed_5pct.pt\",\n",
    "    \"YOLO_OBB_Mixed_Training_Results/yolo26l_mixed_10pct.pt\",\n",
    "    \"YOLO_OBB_Mixed_Training_Results/yolo26l_mixed_20pct.pt\",\n",
    "    \"YOLO_OBB_Mixed_Training_Results/yolo26l_mixed_30pct.pt\",\n",
    "    \"YOLO_OBB_Mixed_Training_Results/yolo26l_mixed_40pct.pt\",\n",
    "    \"YOLO_OBB_FineTuning_Results/yolo_obb_scratch_alpha_baseline_40.pt\",\n",
    "    \"YOLO_OBB_Mixed_Training_Results/YOLO26l_OBB_Real_Data_only.pt\",\n",
    "    \"YOLO_OBB_Mixed_Training_Results/YOLO26l_OBB_E1_Synthesized_only.pt\"\n",
    "    \n",
    "]\n",
    "results_summary = {}\n",
    "test_yaml = create_test_yaml(TEST_DATASET_PATH, \"test_v3_finetune\")\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    model_path = Path(model_name)\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"Model {model_name} not found at {model_path.resolve()}. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        # Extract valid run name for wandb\n",
    "        run_name = model_path.parent.parent.name # e.g. yolo_obb_ft_5pct\n",
    "        \n",
    "        metrics = model.val(data=str(test_yaml), split='test', project=WANDB_PROJECT, name=f\"test_{run_name}\")\n",
    "        \n",
    "        results_summary[model_name] = {\n",
    "            \"map50\": metrics.box.map50,\n",
    "            \"map50-95\": metrics.box.map,\n",
    "            \"precision\": metrics.box.mp,  # mean precision\n",
    "            \"recall\": metrics.box.mr      # mean recall\n",
    "        }\n",
    "        print(f\"Result for {model_name}:\")\n",
    "        print(f\"  mAP50={metrics.box.map50:.4f}, mAP50-95={metrics.box.map:.4f}\")\n",
    "        print(f\"  Precision={metrics.box.mp:.4f}, Recall={metrics.box.mr:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {model_name}: {e}\")\n",
    "\n",
    "print(\"\\n=== FINAL RESULTS ===\")\n",
    "for m, res in results_summary.items():\n",
    "    print(f\"{m}:\")\n",
    "    print(f\"  mAP50={res['map50']:.4f}, mAP50-95={res['map50-95']:.4f}\")\n",
    "    print(f\"  Precision={res['precision']:.4f}, Recall={res['recall']:.4f}\")\n",
    "\n",
    "# Save results to file\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = Path(\"YOLO_OBB_Mixed_Training_Results/test_results_last\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save as JSON\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "json_file = results_dir / f\"test_results_{timestamp}.json\"\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=4)\n",
    "print(f\"\\nResults saved to: {json_file}\")\n",
    "\n",
    "# Save as formatted text file\n",
    "txt_file = results_dir / f\"test_results_{timestamp}.txt\"\n",
    "with open(txt_file, 'w') as f:\n",
    "    f.write(\"=== MODEL EVALUATION RESULTS ===\\n\")\n",
    "    f.write(f\"Test Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    \n",
    "    for m, res in results_summary.items():\n",
    "        f.write(f\"Model: {m}\\n\")\n",
    "        f.write(f\"  mAP50:     {res['map50']:.4f}\\n\")\n",
    "        f.write(f\"  mAP50-95:  {res['map50-95']:.4f}\\n\")\n",
    "        f.write(f\"  Precision: {res['precision']:.4f}\\n\")\n",
    "        f.write(f\"  Recall:    {res['recall']:.4f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "print(f\"Results saved to: {txt_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}