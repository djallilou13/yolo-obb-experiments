{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trolley YOLO-OBB Training (Real Data)\n",
    "\n",
    "This notebook trains a YOLO-OBB model on Real-World data.\n",
    "\n",
    "**Workflow:**\n",
    "1. **Environment Setup**: Install and import required libraries.\n",
    "2. **Configuration**: Set constants and seeds.\n",
    "3. **Data Augmentation**: Define geometric and color augmentations.\n",
    "4. **Data Preparation**: Split real data into Train/Val respecting existing splits.\n",
    "5. **Format Conversion**: Convert polygon annotations to OBB format.\n",
    "6. **Training**: Train the YOLOv8-OBB model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6246c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install -q ultralytics albumentations opencv-python numpy pyyaml tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a496991",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTS = [\".jpg\", \".jpeg\", \".png\"]\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea43ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_params = A.KeypointParams(format=\"xy\", remove_invisible=False)\n",
    "\n",
    "common_augs = {\n",
    "    \"brightness_contrast\": A.Compose([\n",
    "        A.RandomBrightnessContrast(p=0.3)\n",
    "    ], keypoint_params=kp_params),\n",
    "\n",
    "    \"hue_saturation\": A.Compose([\n",
    "        A.HueSaturationValue(p=0.3)\n",
    "    ], keypoint_params=kp_params),\n",
    "\n",
    "    \"gauss_noise\": A.Compose([\n",
    "        A.GaussNoise(p=0.2)\n",
    "    ], keypoint_params=kp_params),\n",
    "\n",
    "    \"motion_blur\": A.Compose([\n",
    "        A.MotionBlur(blur_limit=5, p=0.2)\n",
    "    ], keypoint_params=kp_params),\n",
    "}\n",
    "\n",
    "# Full Geometric Augmentations\n",
    "geo_full = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Rotate(limit=(45, 45), border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
    "        A.Rotate(limit=(90, 90), border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
    "    ], p=0.7)\n",
    "], keypoint_params=kp_params)\n",
    "\n",
    "# Restricted Geometric Augmentations (Horizontal Flip only)\n",
    "geo_restricted = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5)\n",
    "], keypoint_params=kp_params)\n",
    "\n",
    "AUGMENTATIONS_FULL = {**common_augs, \"geometric\": geo_full}\n",
    "AUGMENTATIONS_RESTRICTED = {**common_augs, \"geometric\": geo_restricted}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions\n",
    "Basic file I/O and geometric conversion utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_file(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    return [list(map(float, l.strip().split())) for l in lines]\n",
    "\n",
    "\n",
    "def save_label_file(path, entries):\n",
    "    with open(path, \"w\") as f:\n",
    "        for cls, coords in entries:\n",
    "            f.write(\" \".join([str(cls)] + [f\"{c:.6f}\" for c in coords]) + \"\\n\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def polygon_to_minrect_norm(points, w, h):\n",
    "    if len(points) != 4:\n",
    "        return None\n",
    "\n",
    "    pts = np.array(points, dtype=np.float32)\n",
    "    rect = cv2.minAreaRect(pts)\n",
    "    box = cv2.boxPoints(rect)\n",
    "\n",
    "    norm = []\n",
    "    for x, y in box:\n",
    "        norm.append(x / w)\n",
    "        norm.append(y / h)\n",
    "\n",
    "    return norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Processing Pipeline\n",
    "Logic to gather existing splits and process the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00881dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "\n",
    "# Assuming these are defined elsewhere in your code:\n",
    "# IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "# AUGMENTATIONS_RESTRICTED = ...\n",
    "# AUGMENTATIONS_FULL = ...\n",
    "# polygon_to_minrect_norm = ...\n",
    "# load_label_file = ...\n",
    "# save_label_file = ...\n",
    "\n",
    "\n",
    "def gather_existing_splits(dataset_dirs):\n",
    "    \"\"\"\n",
    "    Scans dataset directories for existing split subfolders.\n",
    "    Supports both structures:\n",
    "      1. ds/images/split_name & ds/labels/split_name\n",
    "      2. ds/split_name/images & ds/split_name/labels\n",
    "    \"\"\"\n",
    "    all_train = []\n",
    "    all_val = []\n",
    "    \n",
    "    # --- 1. Define your exact folder names here ---\n",
    "    splits = ['train(80_ REAL DATA)', 'test(20_ REAL DATA)']\n",
    "\n",
    "    for ds in dataset_dirs:\n",
    "        ds = Path(ds) # Ensure it's a Path object\n",
    "        source_id = ds.name\n",
    "        \n",
    "        for split in splits:\n",
    "            # --- Detect Folder Structure ---\n",
    "            # Check Pattern 1: ds/images/train(...)\n",
    "            p1_img = ds / \"images\" / split\n",
    "            p1_lbl = ds / \"labels\" / split\n",
    "            \n",
    "            # Check Pattern 2: ds/train(...)/images\n",
    "            p2_img = ds / split / \"images\"\n",
    "            p2_lbl = ds / split / \"labels\"\n",
    "\n",
    "            if p1_img.exists() and p1_img.is_dir():\n",
    "                images_dir = p1_img\n",
    "                labels_dir = p1_lbl\n",
    "            elif p2_img.exists() and p2_img.is_dir():\n",
    "                images_dir = p2_img\n",
    "                labels_dir = p2_lbl\n",
    "            else:\n",
    "                # If this specific split folder doesn't exist in this dataset, skip it\n",
    "                continue\n",
    "            \n",
    "            # --- Collect Pairs ---\n",
    "            if not labels_dir.exists():\n",
    "                print(f\"Warning: Labels dir not found for {images_dir}\")\n",
    "                continue\n",
    "\n",
    "            image_files = [p for p in images_dir.iterdir() if p.suffix.lower() in IMG_EXTS]\n",
    "            \n",
    "            count = 0\n",
    "            for img_p in image_files:\n",
    "                lab_p = labels_dir / f\"{img_p.stem}.txt\"\n",
    "                \n",
    "                if lab_p.exists():\n",
    "                    # Create the pair tuple\n",
    "                    pair = (img_p, lab_p, source_id)\n",
    "                    \n",
    "                    # --- 2. Sort into Train or Val based on folder name ---\n",
    "                    # We check if the folder name starts with \"train\" (case insensitive)\n",
    "                    if split.lower().startswith('train'):\n",
    "                        all_train.append(pair)\n",
    "                    else:\n",
    "                        # Everything else (like \"test(20...)\") goes to validation\n",
    "                        all_val.append(pair)\n",
    "                    count += 1\n",
    "            \n",
    "            print(f\"Found {count} pairs in {source_id} [{split}]\")\n",
    "\n",
    "    return all_train, all_val\n",
    "\n",
    "def process_dataset(file_list, mode, output_root):\n",
    "    # output_root should be FINAL_DATASET\n",
    "    img_out_dir = output_root / \"images\" / mode\n",
    "    lab_out_dir = output_root / \"labels\" / mode\n",
    "    img_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    lab_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    excluded_folders = [\"Capture_as_our_dataset\", \"Capture_scene_8\"]\n",
    "    \n",
    "    for img_p, lab_p, source_id in tqdm(file_list, desc=f\"Processing {mode}\"):\n",
    "        # Determine Augmentations\n",
    "        if mode == \"train\":\n",
    "            if source_id in excluded_folders:\n",
    "                active_augs = AUGMENTATIONS_RESTRICTED\n",
    "            else:\n",
    "                active_augs = AUGMENTATIONS_FULL\n",
    "        else:\n",
    "            # Validation: No augmentation, just identity/format conversion\n",
    "            active_augs = {\"origin\": A.Compose([], keypoint_params=A.KeypointParams(format=\"xy\", remove_invisible=False))}\n",
    "            \n",
    "        # Load Image and Label\n",
    "        img = cv2.imread(str(img_p))\n",
    "        if img is None: continue\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        labels = load_label_file(lab_p)\n",
    "        keypoints = []\n",
    "        for lbl in labels:\n",
    "            coords = lbl[1:]\n",
    "            for i in range(0, 8, 2):\n",
    "                keypoints.append((coords[i] * w, coords[i + 1] * h))\n",
    "                \n",
    "        # Apply Augmentations Loop\n",
    "        base_name = f\"{source_id}__{img_p.stem}\"\n",
    "        \n",
    "        for aug_name, aug in active_augs.items():\n",
    "            try:\n",
    "                out = aug(image=img, keypoints=keypoints)\n",
    "                if len(out[\"keypoints\"]) != len(keypoints): continue\n",
    "                \n",
    "                # Convert Back to OBB Norm\n",
    "                entries = []\n",
    "                for i, lbl in enumerate(labels):\n",
    "                    pts = out[\"keypoints\"][i*4 : (i+1)*4]\n",
    "                    rect = polygon_to_minrect_norm(pts, out[\"image\"].shape[1], out[\"image\"].shape[0])\n",
    "                    if rect:\n",
    "                        entries.append((int(lbl[0]), rect))\n",
    "                \n",
    "                if not entries: continue\n",
    "                \n",
    "                # Save\n",
    "                suffix = f\"_{aug_name}\" if mode == \"train\" else \"\"\n",
    "                new_name = f\"{base_name}{suffix}\"\n",
    "                \n",
    "                cv2.imwrite(str(img_out_dir / f\"{new_name}.jpg\"), out[\"image\"])\n",
    "                save_label_file(lab_out_dir / f\"{new_name}.txt\", entries)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_p.name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [Path(\"Real_Data\")]\n",
    "final_output = Path(\"final_dataset_real\")\n",
    "\n",
    "# 1. Gather files respecting existing 'train'/'val' folders\n",
    "train_files, val_files = gather_existing_splits(dataset_paths)\n",
    "\n",
    "# 2. Process them\n",
    "process_dataset(train_files, \"train\", final_output)\n",
    "process_dataset(val_files, \"val\", final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset YAML Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9018af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yaml(out_dir, nc, names):\n",
    "    content = f\"\"\"\n",
    "path: {out_dir.resolve()}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "nc: {nc}\n",
    "names: {names}\n",
    "\"\"\"\n",
    "    with open(out_dir / \"dataset_real.yaml\", \"w\") as f:\n",
    "        f.write(content.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d331673",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml(final_output, nc=1, names=[\"object\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6478e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo26l-obb.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=\"final_dataset_real/dataset_real.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=10,\n",
    "    workers=20,\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    close_mosaic=15,\n",
    "    patience=25,\n",
    "    save_period=10,\n",
    "    val=True,\n",
    "    amp=True,\n",
    "    device=0,\n",
    "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
    "    degrees=10.0,\n",
    "    translate=0.1,\n",
    "    scale=0.9,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.1,\n",
    "    erasing=0.3,\n",
    "    perspective=0.0005,\n",
    "    project=\"paper_experiment\",\n",
    "    name=\"YOLO26l_OBB_E1_Synthesized_only\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
